{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d9bdf22",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef9f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31c803b",
   "metadata": {},
   "source": [
    "## Simulated annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9373fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to generate initial arguments and set lists for ranges and steps\n",
    "def init_arguments(regressor):\n",
    "\targuments = []\n",
    "\n",
    "\tif regressor == \"DecisionTreeRegressor\":\n",
    "\t\tmin_max_values = [[1, 10], [2, 10], [1, 10]]\n",
    "\t\tinteger_values = [True, True, True]\n",
    "\t\tchanges = [[1, 0, -1], [1, 0, -1], [1, 0, -1]]\n",
    "\tif regressor == \"LinearSVR\":\n",
    "\t\tmin_max_values = [[0, 1], [0, 2], [0, 5], [0, 2]]\n",
    "\t\tinteger_values = [True, True, True, True]\n",
    "\t\tchanges = [[1, 0, -1], [1, 0, -1], [1, 0, -1], [1, 0, -1]]\n",
    "\tif regressor == \"KNN\":\n",
    "\t\tmin_max_values = [[1, 10], [0, 1], [1, 2]]\n",
    "\t\tinteger_values = [True, True, True]\n",
    "\t\tchanges = [[1, 0, -1], [1, 0, -1], [1, 0, -1]]\n",
    "\n",
    "\tfor i, mm in enumerate(min_max_values):\n",
    "\t\tif not integer_values or integer_values[i]:\n",
    "\t\t\targuments.append(rd.randint(mm[0], mm[1]))\n",
    "\t\telse:\n",
    "\t\t\targuments.append(rd.uniform(mm[0], mm[1]))\n",
    "\n",
    "\treturn arguments, min_max_values, integer_values, changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e78756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutation_value(value, digit, base):\n",
    "\treturn (value % base**(digit+1)) // base**digit\n",
    "\n",
    "def get_random_full_mutation(arguments, changes, min_max_values):\n",
    "\tchanges_per_value = len(changes[0])\n",
    "\ttotal_changes = len(changes)**changes_per_value\n",
    "\n",
    "\tmutated_arguments = []\n",
    "\n",
    "\ti = rd.randint(0, total_changes)\n",
    "\n",
    "\tmutated_arguments = arguments.copy()\n",
    "\n",
    "\tfor j in range(len(mutated_arguments)):\n",
    "\t\tmutated_arguments[j] += changes[j][get_mutation_value(i, j, changes_per_value)]\n",
    "\t\tmutated_arguments[j] = max(min_max_values[j][0], min(mutated_arguments[j], min_max_values[j][1]))\n",
    "\n",
    "\treturn mutated_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa96d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the negative mean squared error for evaluation\n",
    "def calculate_quality(arguments, regressor, X, y, scoring, n=5):\n",
    "\tif regressor == \"DecisionTreeRegressor\":\n",
    "\t\tregressor  = DecisionTreeRegressor(\n",
    "\t\t\tmax_depth = arguments[0],\n",
    "\t\t\tmin_samples_split = arguments[1],\n",
    "\t\t\tmin_samples_leaf = arguments[2]\n",
    "\t\t\t)\n",
    "\tif regressor == \"LinearSVR\":\n",
    "\t\tloss = [\"epsilon_insensitive\", \"squared_epsilon_insensitive\"]\n",
    "\t\ttol = [1e-5, 1e-3, 1e-1]\n",
    "\t\tC = [1e-4, 1e-2, 0.5, 1, 10, 20]\n",
    "\t\tepsilon = [1e-3, 1e-1, 1]\n",
    "\t\tregressor  = LinearSVR(\n",
    "\t\t\tloss = loss[arguments[0]],\n",
    "\t\t\ttol = tol[arguments[1]],\n",
    "\t\t\tC = C[arguments[2]],\n",
    "\t\t\tepsilon = epsilon[arguments[3]],\n",
    "\t\t\tmax_iter = 4000\n",
    "\t\t\t)\n",
    "\tif regressor == \"KNN\":\n",
    "\t\tweights = [\"uniform\", \"distance\"]\n",
    "\t\tregressor  = KNeighborsRegressor(\n",
    "\t\t\tn_neighbors = arguments[0],\n",
    "\t\t\tweights = weights[arguments[1]],\n",
    "\t\t\tp = arguments[2]\n",
    "\t\t\t)\n",
    "\n",
    "\tcv = cross_val_score(regressor, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "\treturn (sum(cv)/len(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73704b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates a set of argument sets and sorts them\n",
    "def evaluate(mutated_arguments, regressor, X, y, scoring):\n",
    "\treturn [calculate_quality(mutated_arguments, regressor, X, y, scoring), arguments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1472079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simmulated_annealing(X, y, regressor, init_arg, changes, min_max_values, integer_values, scoring):\n",
    "\tbest_arguments = init_arg\n",
    "\tbest_score = evaluate(best_arguments, regressor, X, y, scoring)[0]\n",
    "\tcurrent_arguments = best_arguments\n",
    "\tcurrent_score = best_score\n",
    "\n",
    "\tstart_arguments = best_arguments\n",
    "\tstart_score = best_score\n",
    "\n",
    "\tno_change_since = 0\n",
    "\tmax_no_change_since = 5\n",
    "\n",
    "\tgenerations_to_kill = 2000\n",
    "\n",
    "\ttemperature = 1000\n",
    "\n",
    "\tprint([best_score, best_arguments])\n",
    "\n",
    "\twhile(no_change_since < max_no_change_since and generations_to_kill > 0):\n",
    "\t\t# mutate\n",
    "\t\tmutated_arguments = get_random_full_mutation(current_arguments, changes, min_max_values)\n",
    "\t\t# evaluate\n",
    "\t\tevaluated_arguments = evaluate(mutated_arguments, regressor, X, y, scoring)\n",
    "\n",
    "\t\tnpl = -np.log(np.random.rand()) * temperature\n",
    "\t\tdiff = (current_score - evaluated_arguments[0])\n",
    "\n",
    "\t\tif npl > diff:\n",
    "\t\t\tcurrent_score = evaluated_arguments[0]\n",
    "\t\t\tcurrent_arguments = evaluated_arguments[1]\n",
    "\t\t\tno_change_since = 0\n",
    "\t\telif temperature < 1:\n",
    "\t\t\tno_change_since += 1\n",
    "\n",
    "\t\tif current_score >= best_score:\n",
    "\t\t\tbest_score = current_score\n",
    "\t\t\tbest_arguments = current_arguments\n",
    "\n",
    "\t\ttemperature = 0.9 * temperature\n",
    "\t\tgenerations_to_kill -= 1\n",
    "\n",
    "\treturn best_score, best_arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbda975",
   "metadata": {},
   "source": [
    "## Method calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e357ec0d",
   "metadata": {},
   "source": [
    "### Red wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('../../datasets/wine/wine_red_input.data',delimiter=\";\")\n",
    "y = np.loadtxt('../../datasets/wine/wine_red_classes.data',delimiter=\";\")\n",
    "allScores_red = []\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"DecisionTreeRegressor\")\n",
    "best_score, best_arguments = simmulated_annealing(X, y, \"DecisionTreeRegressor\", arguments, changes, min_max_values, integer_values, \"neg_mean_squared_error\")\n",
    "print(\"DecisionTreeRegressor\", \"nmse\", best_score, best_arguments)\n",
    "allScores_red.append(best_score)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"LinearSVR\")\n",
    "best_score, best_arguments = simmulated_annealing(X, y, \"LinearSVR\", arguments, changes, min_max_values, integer_values, \"neg_mean_squared_error\")\n",
    "print(\"LinearSVR\", \"nmse\", best_score, best_arguments)\n",
    "allScores_red.append(best_score)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"KNN\")\n",
    "best_score, best_arguments = simmulated_annealing(X, y, \"KNN\", arguments, changes, min_max_values, integer_values, \"neg_mean_squared_error\")\n",
    "print(\"KNN\", \"nmse\", best_score, best_arguments)\n",
    "allScores_red.append(best_score)\n",
    "\n",
    "print()\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"DecisionTreeRegressor\")\n",
    "best_score, best_arguments = simmulated_annealing(X, y, \"DecisionTreeRegressor\", arguments, changes, min_max_values, integer_values, \"r2\")\n",
    "print(\"DecisionTreeRegressor\", \"r2\", best_score, best_arguments)\n",
    "allScores_red.append(best_score)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"LinearSVR\")\n",
    "best_score, best_arguments = simmulated_annealing(X, y, \"LinearSVR\", arguments, changes, min_max_values, integer_values, \"r2\")\n",
    "print(\"LinearSVR\", \"r2\", best_score, best_arguments)\n",
    "allScores_red.append(best_score)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"KNN\")\n",
    "best_score, best_arguments = simmulated_annealing(X, y, \"KNN\", arguments, changes, min_max_values, integer_values, \"r2\")\n",
    "print(\"KNN\", \"r2\", best_score, best_arguments)\n",
    "allScores_red.append(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50628745",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "x = ['DecisionTreeRegressor_nmse', 'LinearSVR_nmse', 'KNN_nmse','DecisionTreeRegressor_r2', 'LinearSVR_r2', 'KNN_r2']\n",
    "y = allScores_red\n",
    "\n",
    "ax.bar(x,y)\n",
    "fig.suptitle('Simmulated Annealing red wine quality', fontsize=16)\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed580f",
   "metadata": {},
   "source": [
    "### White wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('../../datasets/wine/wine_white_input.data',delimiter=\";\")\n",
    "y = np.loadtxt('../../datasets/wine/wine_white_classes.data',delimiter=\";\")\n",
    "allScores_white = []\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"DecisionTreeRegressor\")\n",
    "best_score, best_arguments = simmulated_annealing(X, y, \"DecisionTreeRegressor\", arguments, changes, min_max_values, integer_values, \"neg_mean_squared_error\")\n",
    "print(\"DecisionTreeRegressor\", \"nmse\", best_score, best_arguments)\n",
    "allScores_white.append(best_score)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"LinearSVR\")\n",
    "best_score, best_arguments = simmulated_annealing(X, y, \"LinearSVR\", arguments, changes, min_max_values, integer_values, \"neg_mean_squared_error\")\n",
    "print(\"LinearSVR\", \"nmse\", best_score, best_arguments)\n",
    "allScores_white.append(best_score)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"KNN\")\n",
    "best_score, best_arguments = simmulated_annealing(X, y, \"KNN\", arguments, changes, min_max_values, integer_values, \"neg_mean_squared_error\")\n",
    "print(\"KNN\", \"nmse\", best_score, best_arguments)\n",
    "allScores_white.append(best_score)\n",
    "\n",
    "print()\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"DecisionTreeRegressor\")\n",
    "best_score, best_arguments = simmulated_annealing(X, y, \"DecisionTreeRegressor\", arguments, changes, min_max_values, integer_values, \"r2\")\n",
    "print(\"DecisionTreeRegressor\", \"r2\", best_score, best_arguments)\n",
    "allScores_white.append(best_score)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"LinearSVR\")\n",
    "best_score, best_arguments = simmulated_annealing(X, y, \"LinearSVR\", arguments, changes, min_max_values, integer_values, \"r2\")\n",
    "print(\"LinearSVR\", \"r2\", best_score, best_arguments)\n",
    "allScores_white.append(best_score)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"KNN\")\n",
    "best_score, best_arguments = simmulated_annealing(X, y, \"KNN\", arguments, changes, min_max_values, integer_values, \"r2\")\n",
    "print(\"KNN\", \"r2\", best_score, best_arguments)\n",
    "allScores_white.append(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "x = ['DecisionTreeRegressor_nmse', 'LinearSVR_nmse', 'KNN_nmse','DecisionTreeRegressor_r2', 'LinearSVR_r2', 'KNN_r2']\n",
    "y = allScores_white\n",
    "\n",
    "ax.bar(x,y)\n",
    "fig.suptitle('Simmulated Annealing white wine quality', fontsize=16)\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
