{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b31078",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca82fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import random as rd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecfbbad",
   "metadata": {},
   "source": [
    "## Hillclimbing\n",
    "\n",
    "Hillclimbing takes a random initial set of hyperparameter and searches its direct neighborhood for better soltions, repeating the process until no better solution can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5f6111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to generate initial arguments and set lists for ranges and steps\n",
    "def init_arguments(regressor):\n",
    "\targuments = []\n",
    "\n",
    "\tif regressor == \"DecisionTreeRegressor\":\n",
    "\t\tmin_max_values = [[1, 10], [2, 10], [1, 10]]\n",
    "\t\tinteger_values = [True, True, True]\n",
    "\t\tchanges = [[1, 0, -1], [1, 0, -1], [1, 0, -1]]\n",
    "\tif regressor == \"LinearSVR\":\n",
    "\t\tmin_max_values = [[0, 1], [0, 2], [0, 5], [0, 2]]\n",
    "\t\tinteger_values = [True, True, True, True]\n",
    "\t\tchanges = [[1, 0, -1], [1, 0, -1], [1, 0, -1], [1, 0, -1]]\n",
    "\tif regressor == \"KNN\":\n",
    "\t\tmin_max_values = [[1, 10], [0, 1], [1, 2]]\n",
    "\t\tinteger_values = [True, True, True]\n",
    "\t\tchanges = [[1, 0, -1], [1, 0, -1], [1, 0, -1]]\n",
    "\n",
    "\tfor i, mm in enumerate(min_max_values): \n",
    "\t\tif not integer_values or integer_values[i]:\n",
    "\t\t\targuments.append(rd.randint(mm[0], mm[1]))\n",
    "\t\telse:\n",
    "\t\t\targuments.append(rd.uniform(mm[0], mm[1]))\n",
    "\n",
    "\treturn arguments, min_max_values, integer_values, changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154c2114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all argument sets in the direct neighborhood of the given argument set\n",
    "def mutate_arguments_direct_neighborhood(arguments, changes, min_max_values, include_original = True):\n",
    "\tchanges_per_value = len(changes[0])\n",
    "\ttotal_changes = len(changes)**changes_per_value\n",
    "\n",
    "\tmutated_arguments = []\n",
    "\n",
    "\tfor i in range(len(arguments)):\n",
    "\t\tfor j in range(len(changes[i])):\n",
    "\t\t\tnew_arguments = arguments.copy()\n",
    "\t\t\tnew_arguments[i] += changes[i][j]\n",
    "\t\t\tnew_arguments[i] = max(min_max_values[i][0], min(new_arguments[i], min_max_values[i][1]))\n",
    "\t\t\tif (include_original or new_arguments != arguments) and new_arguments not in arguments:\n",
    "\t\t\t\tmutated_arguments.append(new_arguments)\n",
    "\n",
    "\treturn mutated_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the negative mean squared error for evaluation\n",
    "def calculate_quality(arguments, regressor, X, y, scoring, n=5):\n",
    "\tif regressor == \"DecisionTreeRegressor\":\n",
    "\t\tregressor  = DecisionTreeRegressor(\n",
    "\t\t\tmax_depth = arguments[0],\n",
    "\t\t\tmin_samples_split = arguments[1],\n",
    "\t\t\tmin_samples_leaf = arguments[2]\n",
    "\t\t\t)\n",
    "\tif regressor == \"LinearSVR\":\n",
    "\t\tloss = [\"epsilon_insensitive\", \"squared_epsilon_insensitive\"]\n",
    "\t\ttol = [1e-5, 1e-3, 1e-1]\n",
    "\t\tC = [1e-4, 1e-2, 0.5, 1, 10, 20]\n",
    "\t\tepsilon = [1e-3, 1e-1, 1]\n",
    "\t\tregressor  = LinearSVR(\n",
    "\t\t\tloss = loss[arguments[0]],\n",
    "\t\t\ttol = tol[arguments[1]],\n",
    "\t\t\tC = C[arguments[2]],\n",
    "\t\t\tepsilon = epsilon[arguments[3]],\n",
    "\t\t\tmax_iter = 10000,\n",
    "\t\t\t)\n",
    "\tif regressor == \"KNN\":\n",
    "\t\tweights = [\"uniform\", \"distance\"]\n",
    "\t\tregressor  = KNeighborsRegressor(\n",
    "\t\t\tn_neighbors = arguments[0],\n",
    "\t\t\tweights = weights[arguments[1]],\n",
    "\t\t\tp = arguments[2]\n",
    "\t\t\t)\n",
    "\n",
    "\tcv = cross_val_score(regressor, X, y, cv=5, scoring=scoring)\n",
    "\n",
    "\treturn (sum(cv)/len(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc38308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates a set of argument sets and sorts them\n",
    "def evaluate(mutated_arguments, regressor, X, y, scoring):\n",
    "\tevaluated_arguments = []\n",
    "\n",
    "\tfor arguments in mutated_arguments:\t\n",
    "\t\tevaluated_arguments.append([calculate_quality(arguments, regressor, X, y, scoring), arguments])\n",
    "\t\n",
    "\tevaluated_arguments.sort(reverse = False)\n",
    "\t\n",
    "\treturn evaluated_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0288cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_climbing(X, y, regressor, init_arg, changes, min_max_values, integer_values, scoring):\n",
    "\tbest_arguments = init_arg\n",
    "\tbest_score = evaluate([best_arguments], regressor, X, y, scoring)[0][0]\n",
    "\n",
    "\tstart_arguments = best_arguments\n",
    "\tstart_score = best_score\n",
    "\n",
    "\tno_change_since = 0\n",
    "\tmax_no_change_since = 1\n",
    "\n",
    "\twhile(no_change_since < max_no_change_since):\n",
    "\t\t# mutate\n",
    "\t\tmutated_arguments = mutate_arguments_direct_neighborhood(best_arguments, changes, min_max_values)\n",
    "\t\tevaluated_arguments = evaluate(mutated_arguments, regressor, X, y, scoring)\n",
    "\n",
    "\n",
    "\t\tif evaluated_arguments[0][0] < best_score:\n",
    "\t\t\tbest_score = evaluated_arguments[0][0]\n",
    "\t\t\tbest_arguments = evaluated_arguments[0][1]\n",
    "\t\telse:\n",
    "\t\t\tno_change_since+=1\n",
    "\n",
    "\treturn best_score, best_arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b32d1",
   "metadata": {},
   "source": [
    "## Method calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c0e71",
   "metadata": {},
   "source": [
    "### Red wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('../../datasets/wine/wine_red_input.data',delimiter=\";\")\n",
    "y = np.loadtxt('../../datasets/wine/wine_red_classes.data',delimiter=\";\")\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"DecisionTreeRegressor\")\n",
    "best_score, best_arguments = hill_climbing(X, y, \"DecisionTreeRegressor\", arguments, changes, min_max_values, integer_values, \"neg_mean_squared_error\")\n",
    "print(\"DecisionTreeRegressor\", \"nmse\", best_score, best_arguments)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"LinearSVR\")\n",
    "best_score, best_arguments = hill_climbing(X, y, \"LinearSVR\", arguments, changes, min_max_values, integer_values, \"neg_mean_squared_error\")\n",
    "print(\"LinearSVR\", \"nmse\", best_score, best_arguments)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"KNN\")\n",
    "best_score, best_arguments = hill_climbing(X, y, \"KNN\", arguments, changes, min_max_values, integer_values, \"neg_mean_squared_error\")\n",
    "print(\"KNN\", \"nmse\", best_score, best_arguments)\n",
    "\n",
    "print()\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"DecisionTreeRegressor\")\n",
    "best_score, best_arguments = hill_climbing(X, y, \"DecisionTreeRegressor\", arguments, changes, min_max_values, integer_values, \"r2\")\n",
    "print(\"DecisionTreeRegressor\", \"r2\", best_score, best_arguments)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"LinearSVR\")\n",
    "best_score, best_arguments = hill_climbing(X, y, \"LinearSVR\", arguments, changes, min_max_values, integer_values, \"r2\")\n",
    "print(\"LinearSVR\", \"r2\", best_score, best_arguments)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"KNN\")\n",
    "best_score, best_arguments = hill_climbing(X, y, \"KNN\", arguments, changes, min_max_values, integer_values, \"r2\")\n",
    "print(\"KNN\", \"r2\", best_score, best_arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f719c8fc",
   "metadata": {},
   "source": [
    "### White wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672cea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('../../datasets/wine/wine_white_input.data',delimiter=\";\")\n",
    "y = np.loadtxt('../../datasets/wine/wine_white_classes.data',delimiter=\";\")\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"DecisionTreeRegressor\")\n",
    "best_score, best_arguments = hill_climbing(X, y, \"DecisionTreeRegressor\", arguments, changes, min_max_values, integer_values, \"neg_mean_squared_error\")\n",
    "print(\"DecisionTreeRegressor\", \"nmse\", best_score, best_arguments)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"LinearSVR\")\n",
    "best_score, best_arguments = hill_climbing(X, y, \"LinearSVR\", arguments, changes, min_max_values, integer_values, \"neg_mean_squared_error\")\n",
    "print(\"LinearSVR\", \"nmse\", best_score, best_arguments)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"KNN\")\n",
    "best_score, best_arguments = hill_climbing(X, y, \"KNN\", arguments, changes, min_max_values, integer_values, \"neg_mean_squared_error\")\n",
    "print(\"KNN\", \"nmse\", best_score, best_arguments)\n",
    "\n",
    "print()\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"DecisionTreeRegressor\")\n",
    "best_score, best_arguments = hill_climbing(X, y, \"DecisionTreeRegressor\", arguments, changes, min_max_values, integer_values, \"r2\")\n",
    "print(\"DecisionTreeRegressor\", \"r2\", best_score, best_arguments)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"LinearSVR\")\n",
    "best_score, best_arguments = hill_climbing(X, y, \"LinearSVR\", arguments, changes, min_max_values, integer_values, \"r2\")\n",
    "print(\"LinearSVR\", \"r2\", best_score, best_arguments)\n",
    "\n",
    "arguments, min_max_values, integer_values, changes = init_arguments(\"KNN\")\n",
    "best_score, best_arguments = hill_climbing(X, y, \"KNN\", arguments, changes, min_max_values, integer_values, \"r2\")\n",
    "print(\"KNN\", \"r2\", best_score, best_arguments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
